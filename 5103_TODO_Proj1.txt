Todo for project:

Unsorted:
-Change cli.py so that we can run all desired test cases (main new one: random file sizes)
	-Write up the series of cli.py arguments that we will use to generate the
	data for our writeup.. this will make the writeup easier
-Do the writeup (at the end .. ?)

EVERYONE:
-Change code so that we can measure “throughput”! 
	-Connor idea: In my implementation, I have an array that has (start, end) times
	-Could make it (start, end, size), and add to ‘size’ after each read!
	-Not sure how you two are doing timing, but if you like this you can steal
-When done changing code, test to make sure it compiles, runs with no errors basically all the time.
-Write a paragraph or two each about the ‘flow of control’, changing between OS and user… based on syscalls. Shouldn't be too difficult with some googling around.



Connor:
-keep organizing todos etc (this is a decent amount of work)
-get 10,000 clients working
-Check if caesar works, follow up w/ Jane/Karel if not and make a new TODO

Jane:
-Fix timing (feel free to copy/paste some of Connor’s code)
-Get 10,0000 threads (or whatever) working - might mean not making new threads until others have finished.

Karel
-Implement timing (if you haven’t) and see if you get similar results to us
	-BENCHMARK: 700,000usec for 30 clients @ 3MB/clients. try diff loads too 
-Address (or not, if it doesn’t need to be) the issue of asychronity in reading. If the prev. bullet (timing) works, then you can probably skip this
-Make it so that running 10,000 threads works and never crashes. The risk of a single crash is potentially pretty bad
	-If you figure this out soon, let Connor know!
